<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>CloudComputing on 奇迹之流WonderfloW</title>
    <link>https://wonderflow.info/categories/cloudcomputing/</link>
    <description>Recent content in CloudComputing on 奇迹之流WonderfloW</description>
    <generator>Hugo</generator>
    <language>zh-cn</language>
    <lastBuildDate>Wed, 17 Dec 2014 08:08:26 +0000</lastBuildDate>
    <atom:link href="https://wonderflow.info/categories/cloudcomputing/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>cf-release结构解析</title>
      <link>https://wonderflow.info/posts/2014/12/17/cf-releasee7bb93e69e84e8a7a3e69e90/</link>
      <pubDate>Wed, 17 Dec 2014 08:08:26 +0000</pubDate>
      <guid>https://wonderflow.info/posts/2014/12/17/cf-releasee7bb93e69e84e8a7a3e69e90/</guid>
      <description>&lt;h1 id=&#34;1-制作时的cf-release结构解析&#34;&gt;&#xA;    1. 制作时的cf-release结构解析&lt;a class=&#34;hash-link&#34; href=&#34;#1-%e5%88%b6%e4%bd%9c%e6%97%b6%e7%9a%84cf-release%e7%bb%93%e6%9e%84%e8%a7%a3%e6%9e%90&#34; title=&#34;Direct link to heading&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&lt;p&gt;此处指的release统一为CloudFoundry官方给出的&lt;a href=&#34;https://github.com/cloudfoundry/cf-release&#34;&gt;cf-release&lt;/a&gt;，不做修改。&lt;/p&gt;&#xA;&lt;p&gt;1.1. 通过载入cf-release文件夹下config/final.yml文件，获得需要下载release文件的远程服务器网址，默认使用的提供商是s3，地址是：blob.cfblob.com&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;http://www.sel.zju.edu.cn/wp-content/uploads/2014/12/link.jpg&#34;&gt;&lt;img src=&#34;http://www.sel.zju.edu.cn/wp-content/uploads/2014/12/link-1024x585.jpg&#34; alt=&#34;link&#34;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;1.2. 通过config/blobs.yml，可以得到所有blobs的object_id，通过服务器地址+object_id拼接的字符串即可下载到相对应的blob内容。&lt;/p&gt;&#xA;&lt;p&gt;1.3. 默认存储的位置为cf-release/.blobs，存储的文件名为sha1值，下载完成后会在cf-release/blobs文件夹下创建以package真实名字命名的软链接到.blobs里面各个具体的包。&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;http://www.sel.zju.edu.cn/wp-content/uploads/2014/12/install.jpg&#34;&gt;&lt;img src=&#34;http://www.sel.zju.edu.cn/wp-content/uploads/2014/12/install-1024x393.jpg&#34; alt=&#34;install&#34;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;1.4. 下载完所有的blobs后，开始对照cf-release/packages文件夹下各个包的spec文件逐个在blobs文件夹下找到，然后拷贝到.final_builds或者.dev_builds，根据是否加了&amp;ndash;final参数决定。拷贝前会执行预安装脚本prepackaging，检查文件是否都存在，做一些单元测试等。执行完后把prepackaging脚本删除后压缩文件夹。&lt;/p&gt;&#xA;&lt;p&gt;(&lt;strong&gt;TIPS&lt;/strong&gt;：有时候某些不需要部署的组件，却因为过不了prepacking脚本的执行导致release做不出来，可以把prepackaging脚本删掉再制作，会自动跳过这个执行过程。)&lt;/p&gt;&#xA;&lt;p&gt;1.5. 对所有cf-release/jobs进行的操作相对简单，除了拷贝到.final_builds或者.dev_builds以外，通过spec文件检查template等文件是否齐全。&lt;/p&gt;&#xA;&lt;p&gt;1.6. 最后生成releases/cf-#{version}.yml文件,在dev_releases文件夹下生成cf-{version}.dev.yml&lt;/p&gt;&#xA;&lt;p&gt;release就算初步制作完成了。&lt;/p&gt;&#xA;&lt;h1 id=&#34;2-部署时的cf-release结构解析&#34;&gt;&#xA;    2. 部署时的cf-release结构解析&lt;a class=&#34;hash-link&#34; href=&#34;#2-%e9%83%a8%e7%bd%b2%e6%97%b6%e7%9a%84cf-release%e7%bb%93%e6%9e%84%e8%a7%a3%e6%9e%90&#34; title=&#34;Direct link to heading&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&lt;p&gt;&lt;a href=&#34;http://www.sel.zju.edu.cn/wp-content/uploads/2014/12/%E8%A7%A3%E6%9E%90%E8%BF%87%E7%A8%8B.jpg&#34;&gt;&lt;img src=&#34;http://www.sel.zju.edu.cn/wp-content/uploads/2014/12/%E8%A7%A3%E6%9E%90%E8%BF%87%E7%A8%8B-1024x1024.jpg&#34; alt=&#34;解析过程&#34;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;2.1. 获得cf-release的配置文件： 扫描./releases以及./dev_releases文件夹，对其中的release配置文件进行排序，排序规则为数字大的优先，相同大小的数字以小数点后大的优先，两个数字都相同取没有dev标记的。 194 &amp;gt; 193 194.1 &amp;gt; 194 194.1 &amp;gt; 194.1-dev 这里得到的最新的文件，就是定义当前release包所有版本的配置文件，称之为@release。&lt;/p&gt;&#xA;&lt;p&gt;2.2. 获取部署配置文件manifest/cf.yml中，要部署的job构成的所有template。部署时定义的job在配置文件中包含多个template，每个template由多个package组成。&lt;/p&gt;&#xA;&lt;p&gt;{% codeblock %}&#xA;`&amp;mdash;&#xA;deployment: cf&#xA;jobs:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;name: nats&#xA;template:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;nats&lt;/li&gt;&#xA;&lt;li&gt;nats_stream_forwarder&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;name: nfs_server&#xA;template:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;debian_nfs_server&#xA;`&#xA;{% endcodeblock %}&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;2.3. 对于2.2中找出的每个template，找到其在@release文件中的version编号以及sha1值（jobs属性下），然后找到.final_builds/jobs下对应的index.yml和.dev_builds/jobs下对应的index.yml，比对两个文件中的sha1，找到对应的版本。此时我们就获得了template的全部具体信息，称之为@template。&lt;/p&gt;&#xA;&lt;p&gt;2.4. @template下有个压缩包，后缀为.tgz，解压缩后得到job.MF文件，可获得该template的所有配置文件，配置文件需要的属性以及依赖的packages。也就是这里，我们获得了构成这个template的所有packages名字。然后我们对照之前的@release文件，又可以得到具体每个package需要的版本。&lt;/p&gt;&#xA;&lt;p&gt;2.5. 值得注意的是，每个template由一个或多个packages构成，而每个package，由零个或多个其他packages构成，而每个package依赖哪些其它package，也在@release文件中的packages栏目下。&lt;/p&gt;</description>
    </item>
    <item>
      <title>北京container技术大会</title>
      <link>https://wonderflow.info/posts/2014/10/22/e58c97e4baaccontainere68a80e69cafe5a4a7e4bc9a/</link>
      <pubDate>Wed, 22 Oct 2014 03:31:08 +0000</pubDate>
      <guid>https://wonderflow.info/posts/2014/10/22/e58c97e4baaccontainere68a80e69cafe5a4a7e4bc9a/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://app.yinxiang.com/shard/s29/sh/db4cbf8e-eed7-45cd-89f0-1bca3a3512f3/e0188caf5e8b92181568798330f5356a&#34;&gt;可以看我的印象笔记共享，格式更加漂亮一些。&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;此次去北京参加的container大会，主办方为csdn，实际会议主持为docker中文社区创始人马全一。会议时间为一天，从早上九点开始一直到晚上六点结束，共包含16个主题。虽说是container大会，但实际上基本围绕docker展开。期间也讲到了社区较为火热的IaaS平台openstack，以及PaaS平台Cloudfoundry，总的来说收获颇丰。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;会议流程：&lt;/strong&gt; &lt;img src=&#34;http://raw.githubusercontent.com/wonderflow/pic/master/container_con_flow.png&#34; alt=&#34;会议流程&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;以下我将按每个有收获的主题分别讲述我的思考和总结。&lt;/p&gt;&#xA;&lt;h1 id=&#34;jromehello-container-ops&#34;&gt;&#xA;    Jrome（Hello Container Ops）&lt;a class=&#34;hash-link&#34; href=&#34;#jromehello-container-ops&#34; title=&#34;Direct link to heading&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&lt;p&gt;正如会议流程所示，第一个讲的是docker的开发工程师Jrome。我觉得他讲述了以下两点比较有意思： 1. docker container的应用场景： 1.1 Web applications 1.2 API backends 1.3 Databases (SQL, NoSQL) 1.4 Big data 1.5 Message queues 总的来说就是涵盖了几乎所有linux server下的工作负载，并且是跨linux不同版本的，据说后面还会加入windows的支持。 2. docker的优势/为什么用docker 2.1 非常轻，以容器做隔离性能损失极小。 2.2 平台无关性使开发、上线流程一体化，减轻了大量运维工作。 2.3 使用dockerfile对镜像高度可定制 2.4 部署、迁移，快速、稳定、简便 2.5 镜像的层级化使使管理非常方便，极易备份恢复等 2.6 共享宿主机使文件和信息共享变得非常方便(volume)&lt;/p&gt;&#xA;&lt;h1 id=&#34;喻勇孙宏亮container技术在cloudfoundry中的演化&#34;&gt;&#xA;    喻勇&amp;amp;孙宏亮（container技术在cloudfoundry中的演化）&lt;a class=&#34;hash-link&#34; href=&#34;#%e5%96%bb%e5%8b%87%e5%ad%99%e5%ae%8f%e4%ba%aecontainer%e6%8a%80%e6%9c%af%e5%9c%a8cloudfoundry%e4%b8%ad%e7%9a%84%e6%bc%94%e5%8c%96&#34; title=&#34;Direct link to heading&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&lt;p&gt;关于这一项，宏亮学长的内容讲的很精彩，可以在实验室找机会给大家也分享一下这一块内容，在此就略过不表。&lt;/p&gt;&#xA;&lt;p&gt;其中Frank(喻勇)除了介绍diego以外，还提到的几点让我感到非常有收获： 1. cloudfoundry现有的不足之处： 1.1 组件内部设计紧耦合,当时设计的时候就没有考虑到要再分割。 1.2 cloud_controller的负载过重，什么事情都要经过它 1.3 复杂的交互形成环状的依赖，使新功能不易添加，老的功能也不易维护。 1.4 Domain Specic，所有应用都是appname.[domain]，固定的模式使应用想要使用/扩展一个新域名变得非常苦难。 1.5 platform Specic，几乎只能稳定运行在linux ubuntu平台上 1.6 ruby编写的dea使应用处理效率低下 2. 容器技术影响未来PaaS的走向 2.1 从软件开发的角度看，开发测试和软件发布的流程都会发生较大的变化。产生诸如： * 产品化的container生命周期管理方案 * 多container复杂应用协同工作 * image host交互（类似github） * image的静态安全性&lt;/p&gt;</description>
    </item>
    <item>
      <title>为什么选择Bosh而不用Puppet/Chef</title>
      <link>https://wonderflow.info/posts/2014/03/17/e4b8bae4bb80e4b988e98089e68ba9boshe8808ce4b88de794a8puppetchef/</link>
      <pubDate>Mon, 17 Mar 2014 06:44:24 +0000</pubDate>
      <guid>https://wonderflow.info/posts/2014/03/17/e4b8bae4bb80e4b988e98089e68ba9boshe8808ce4b88de794a8puppetchef/</guid>
      <description>&lt;p&gt;总的来说，Puppet/Chef是配置管理（Configration Management）工具，Bosh是云管理（Cloud Orchestration）工具。&lt;/p&gt;&#xA;&lt;p&gt;Bosh的功能包含了Puppet/Chef所有的功能，并且Bosh把IaaS和PaaS的管理工作结合了起来并且实现了自动化，节省了大量的工作。但是Bosh需要IaaS层提供API，并且需要专门为API编写Bosh适配的CPI（Cloud Provider Interface），故而部署和使用的要求较高。&lt;/p&gt;&#xA;&lt;p&gt;与此同时，Puppet/Chef工具自2000年起就已开始被广泛使用，其标准化的配置流程也渐渐成为了业界标准。因为其小巧灵活的特性，所以使用要求较低。与Bosh相比，除了配置管理相关的工作以外，还需要人工的去做配置网络、管理虚拟机、版本控制管理等等其他工作，使用起来较为繁琐。&lt;/p&gt;&#xA;&lt;p&gt;目前针对Cloud Foundry的部署，基本有两种大众化的解决方案。&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;使用Bosh，以及拥有Bosh CPI的IaaS平台。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;使用vagrant管理虚拟机，使用puppet/chef来部署。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;而第2点则更多的用于在物理机上部署Cloud Foundry或者在个人开发机上部署CF环境。&lt;/p&gt;&#xA;&lt;p&gt;另外，Stark &amp;amp; Wayne 公司的CEO Dr Nic Williams在介绍为什么使用bosh的时候也说道，Bosh为开发人员、测试人员、部署人员配置了一套统一的环境，免去了很多不必要的麻烦和工作，使得工作变得更加简单了。&lt;/p&gt;&#xA;&lt;p&gt;相比之下，使用bosh进行部署确实如Dr Nic Williams所言，“It makes life easier !”&lt;/p&gt;&#xA;&lt;p&gt;下面详细介绍一下两个工具。&lt;/p&gt;&#xA;&lt;h1 id=&#34;puppet简介&#34;&gt;&#xA;    PUPPET简介&lt;a class=&#34;hash-link&#34; href=&#34;#puppet%e7%ae%80%e4%bb%8b&#34; title=&#34;Direct link to heading&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&lt;p&gt;Puppet是基于Ruby的开源系统配置管理工具，依赖于C/S的部署架构。主要开发者是Luke Kanies，遵循GPL v2版权协议。&lt;/p&gt;&#xA;&lt;p&gt;作为一款配置管理工具，Puppet除包含正常的配置管理工具的功能外，它还有跨平台的特性。Puppet的语法允许你创建一个单独脚本，用来在你所有的目标主机上建立一个用户。所有的目标主机会依次使用适用于本地系统的语法解释和执行这个模块。（举例：如果这个配置是在Red Hat服务器上执行，建立用户使用useradd命令；如果这个配置是在FreeBSD主机上执行，使用的是adduser命令。）&lt;/p&gt;&#xA;&lt;p&gt;Puppet使用跨平台语言规范，管理配置文件、用户、软件包、系统服务等内容，在Puppet里这些内容都被看做是“资源”，每种资源都有对应的属性，如软件包有安装、不安装的属性，文件有权限属性等。Puppet的代码主要由这些资源和其属性组成。其代码化的好处：分享，保存，快速的恢复和部署。&lt;/p&gt;&#xA;&lt;h2 id=&#34;puppet架构&#34;&gt;&#xA;    Puppet架构&lt;a class=&#34;hash-link&#34; href=&#34;#puppet%e6%9e%b6%e6%9e%84&#34; title=&#34;Direct link to heading&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;http://raw.github.com/wonderflow/pic/master/puppet.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;Puppet是一个C/S架构的配置管理工具，在中央服务器上安装puppet-server软件包（被称作Puppet master）。在需要管理的目标主机上安装puppet客户端软件（被称作Puppet Client）。当客户端连接上Puppet master后，定义在Puppet master上的配置文件会被编译，然后在客户端上运行。每个客户端默认每半个小时和服务器进行一次通信，确认配置信息的更新情况。如果有新的配置信息或者配置信息已经改变，配置将会被重新编译并发布到各客户端执行。也可以在服务器上主动触发一个配置信息的更新，强制各客户端进行配置。如果客户端的配置信息被改变了，它可以从服务器获得原始配置进行校正。&lt;/p&gt;&#xA;&lt;p&gt;同时，Puppet也是易于扩展的。定制软件包的支持功能和特殊的系统环境配置能够快速简单的添加进Puppet的安装程序中。作为一款开源的工具，Puppet社区正快速壮大，并且许多新的想法不断融入，促使开发、更新和模块每天都在呈现。&lt;/p&gt;&#xA;&lt;h1 id=&#34;vagrant简介&#34;&gt;&#xA;    Vagrant简介&lt;a class=&#34;hash-link&#34; href=&#34;#vagrant%e7%ae%80%e4%bb%8b&#34; title=&#34;Direct link to heading&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&lt;p&gt;Vagrant 是一个虚拟机管理工具，非常适合用于搭建开发环境。它提供了一套易用的配置规则，比人工操作或者使用虚拟机软件提供的命令行要方便，且可重复。Vagrant最大的用途就是为开发团队配置统一的开发环境，与不同平台的虚拟机供应商结合，无论开发人员用的是 Windows 还是 Mac，都可以跑一个一致的 Linux 开发环境。&lt;/p&gt;&#xA;&lt;p&gt;目前用的最广的是开源的虚拟机VirtualBox。另外VMware等其他供应商的产品也支持，但是需要收费。&lt;/p&gt;&#xA;&lt;p&gt;而与IaaS层的结合使用方面，并没有明确的官方支持，官方只是提供了插件的编写方式允许开发者自行编写插件。&#xA;目前开源社区Github上存在&lt;a href=&#34;https://github.com/mitchellh/vagrant-aws&#34;&gt;AWS&lt;/a&gt;、&lt;a href=&#34;https://github.com/klarna/vagrant-cloudstack&#34;&gt;CloudStack&lt;/a&gt;以及&lt;a href=&#34;https://github.com/FlaPer87/vagrant-openstack&#34;&gt;OpenStack&lt;/a&gt;的插件。&lt;/p&gt;&#xA;&lt;p&gt;Vagrant启动虚拟机后，默认是跑在后台，并且不显示图形界面的，这时候需要用 ssh 连接虚拟机。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Cloud_Controller_NG源码阅读记录</title>
      <link>https://wonderflow.info/posts/2014/02/28/cloud_controller_nge6ba90e7a081e99885e8afbbe8aeb0e5bd95/</link>
      <pubDate>Fri, 28 Feb 2014 04:14:33 +0000</pubDate>
      <guid>https://wonderflow.info/posts/2014/02/28/cloud_controller_nge6ba90e7a081e99885e8afbbe8aeb0e5bd95/</guid>
      <description>&lt;h1 id=&#34;cloud_controller_ng源码阅读记录&#34;&gt;&#xA;    Cloud_Controller_NG源码阅读记录&lt;a class=&#34;hash-link&#34; href=&#34;#cloud_controller_ng%e6%ba%90%e7%a0%81%e9%98%85%e8%af%bb%e8%ae%b0%e5%bd%95&#34; title=&#34;Direct link to heading&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&lt;p&gt;@(CC阅读)[cloud controller] by wonderflow&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;Cloud_Controller_NG就是cloud controller next generation的意思。即Cloud Foundry 平台用来管理控制应用和服务的组件。&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;http://docs.cloudfoundry.com/docs/using/terms.html#ccng&#34;&gt;官方文档&lt;/a&gt;是这么解释CCNG的作用的：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;维护一个包含应用、服务、配置信息的数据库(CCDB)。&lt;/li&gt;&#xA;&lt;li&gt;在blobstore中存储应用的packages和droplets。&lt;/li&gt;&#xA;&lt;li&gt;通过NATS和其他组件进行通信，包括Droplet Execution Agents (DEAs)、Service Gateways、和 Health Manager（HM）。&lt;/li&gt;&#xA;&lt;li&gt;其他供用户调用的后端API。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;阅读该组件源码，有助于从应用管理的视角理解cloudfoundry的运行过程。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;说明：&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Cloud_Controller_NG以下简称CCNG。&lt;/li&gt;&#xA;&lt;li&gt;本文所阅读的源码版本为github中cf-release中V145 tag下面的CCNG项目源码。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;hr&gt;&#xA;&lt;h1 id=&#34;ccng各模块概览&#34;&gt;&#xA;    CCNG各模块概览&lt;a class=&#34;hash-link&#34; href=&#34;#ccng%e5%90%84%e6%a8%a1%e5%9d%97%e6%a6%82%e8%a7%88&#34; title=&#34;Direct link to heading&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&lt;p&gt;首先让我们看一下这张框架图：&#xA;&lt;img src=&#34;https://wonderflow.info/images/2014-02-28-cloud_controller_nge6ba90e7a081e99885e8afbbe8aeb0e5bd95/ccng.png&#34; alt=&#34;Alt text&#34;&gt;&#xA;&lt;strong&gt;图1.CCNG架构图byshlallen&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;从ccng架构图中可以看出ccng可以分为以下多个模块：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Stager模块，主要负责与DEA组件的staging部分进行交互；&lt;/li&gt;&#xA;&lt;li&gt;DEA模块，主要负责与DEA组件进行交互；&lt;/li&gt;&#xA;&lt;li&gt;Blobstore模块，主要负责创建一个blobstore的存储，以供Cloud Foundry存储应用所需的静态文件；&lt;/li&gt;&#xA;&lt;li&gt;HealthManager（HM）模块，主要负责与HealthManager组件进行交互；&lt;/li&gt;&#xA;&lt;li&gt;CCDB模块，负责维护cloud_controller的数据库；&lt;/li&gt;&#xA;&lt;li&gt;collector_registrar模块，负责作为component向Collector组件注册；&lt;/li&gt;&#xA;&lt;li&gt;router_registrar模块，负责将cloud controller组件的域名注册至Router组件；&lt;/li&gt;&#xA;&lt;li&gt;legacy_api部分，负责接管ccng关于info，bulk以及services等的RESTful请求；&lt;/li&gt;&#xA;&lt;li&gt;Permission模块，负责各种不同权限用户的注册和认证。&lt;/li&gt;&#xA;&lt;li&gt;其他零散模块&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;我们按官方文档给出的组件功能介绍的顺序逐步深入各模块。&lt;/p&gt;&#xA;&lt;h2 id=&#34;db模块&#34;&gt;&#xA;    DB模块&lt;a class=&#34;hash-link&#34; href=&#34;#db%e6%a8%a1%e5%9d%97&#34; title=&#34;Direct link to heading&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&lt;p&gt;众所周知，CCDB就是CC的一个postgresql数据库，用于存储CC需要的一些数据。&lt;/p&gt;&#xA;&lt;p&gt;在CCNG的rakefile里面，有着CCDB建表的初始化信息，具体的建表内容在&lt;code&gt;db/migrations/*.rb&lt;/code&gt;中。&lt;/p&gt;&#xA;&lt;p&gt;CCNG开始正常运行后，主要调用lib/sequel_plugins/update_or_create.rb里面的函数对以下信息的改变进行更新（更新的代码都在以下各部分的源码中，可以使用全文搜索update_or_create函数查看）。&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;framework：语言运行时框架。就是&lt;code&gt;&amp;quot;*.war&amp;quot;&lt;/code&gt;包可上传的各种框架，在&lt;code&gt;/var/vcap/jobs/cloud_controller/config/staging&lt;/code&gt;路径下的各类*.yml存储。@&lt;code&gt;lib/cloud_controller/models/framework.rb&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;stack ：应用运行的堆环境，默认为lucid64。&lt;a href=&#34;http://docs.cloudfoundry.com/docs/running/architecture/stacks.html&#34;&gt;stacks&lt;/a&gt;就是一个预先构建的文件系统，包括可运行应用的操作系统环境。@&lt;code&gt;lib/cloud_controller/models/stack.rb&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;runtime：应用可运行语言的运行时环境。运行时环境的具体信息在配置文件&lt;code&gt;config/runtimes.yml&lt;/code&gt;中。@&lt;code&gt;lib/cloud_controller/models/runtime.rb&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;quota：一些共享信息的更新，包括sevice数量，内存限制等。@&lt;code&gt;lib/cloud_controller/models/quota_definition.rb&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;service：存储支持的service信息。@&lt;code&gt;app/models/services/service_broker.rb&lt;/code&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;blobstore模块&#34;&gt;&#xA;    Blobstore模块&lt;a class=&#34;hash-link&#34; href=&#34;#blobstore%e6%a8%a1%e5%9d%97&#34; title=&#34;Direct link to heading&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&lt;p&gt;**注：**blobstor相关源码都@&lt;code&gt;lib/cloud_controller/blobstore&lt;/code&gt;文件夹下&lt;/p&gt;</description>
    </item>
    <item>
      <title>&#39;《MapReduce Design Patterns》读书笔记——浅谈Map/Reduce设计模式 &#39;</title>
      <link>https://wonderflow.info/posts/2013/12/15/e3808amapreduce-design-patternse3808be8afbbe4b9a6e7ac94e8aeb0-e6b585e8b088mapreducee8aebee8aea1e6a8a1e5bc8f/</link>
      <pubDate>Sun, 15 Dec 2013 15:48:24 +0000</pubDate>
      <guid>https://wonderflow.info/posts/2013/12/15/e3808amapreduce-design-patternse3808be8afbbe4b9a6e7ac94e8aeb0-e6b585e8b088mapreducee8aebee8aea1e6a8a1e5bc8f/</guid>
      <description>&lt;h1 id=&#34;概述&#34;&gt;&#xA;    概述&lt;a class=&#34;hash-link&#34; href=&#34;#%e6%a6%82%e8%bf%b0&#34; title=&#34;Direct link to heading&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&lt;p&gt;MapReduce是一个基于Hadoop的算法框架。本文将从Hadoop开始介绍，然后重点讲述可用于Hadoop上的Map/Reduce设计模式。&lt;/p&gt;&#xA;&lt;h1 id=&#34;hadoop简介&#34;&gt;&#xA;    Hadoop简介&lt;a class=&#34;hash-link&#34; href=&#34;#hadoop%e7%ae%80%e4%bb%8b&#34; title=&#34;Direct link to heading&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&lt;h2 id=&#34;hadoop历史&#34;&gt;&#xA;    Hadoop历史&lt;a class=&#34;hash-link&#34; href=&#34;#hadoop%e5%8e%86%e5%8f%b2&#34; title=&#34;Direct link to heading&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&lt;p&gt;Hadoop最早起源于Apache Nutch，该项目始于2002年，是Apache Lucence的子项目之一。该项目的出现源于两篇论文，一篇是2003年发表的“关于谷歌分布式文件系统”（NDFS：Nutch Distributed File System），描述了谷歌搜索引擎网页相关数据存储架构，解决Nutch遇到的网页抓取和索引过程中产生的超大文件存储需求问题。一篇是2004年发表的“关于谷歌分布式计算框架MapReduce”，描述了谷歌内部最重要分布式计算框架，该框架可用于处理海量网页索引问题。由于NDFS和MapReduce在Nutch引擎中有着良好的应用，所以它们于2006年2月被分离出来成为一套独立的软件，命名为Hadoop。&lt;/p&gt;&#xA;&lt;h2 id=&#34;hadoop功能与优势&#34;&gt;&#xA;    Hadoop功能与优势&lt;a class=&#34;hash-link&#34; href=&#34;#hadoop%e5%8a%9f%e8%83%bd%e4%b8%8e%e4%bc%98%e5%8a%bf&#34; title=&#34;Direct link to heading&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&lt;p&gt;近年来，随着现代社会信息的飞速增长，大数据与云计算的概念已经越来越火。预计到2020年，互联网中产生的数字信息将会有三分之一的内容驻留在云平台中交由云平台处理。如何高效的存储和管理这些数据就成为了我们亟需解决的问题，这时Hadoop系统的优势就体现出来了。Hadoop通过三个方面高效的解决了云平台数据存储与管理的问题。一、它采用分布式存储方式HDFS（Hadoop Distributed File System）来提高读写速度和扩大存储容量；二、它采用MapReduce计算框架，分割数据进行分发到分布式文件系统中进行处理，然后再把处理过后的数据进行整合，保证了数据处理的高速；三、它采用存储冗余数据的方式来保证数据的安全性。用户可以轻松的架构并使用Hadoop系统，它主要具有四个优点：高可靠性、高扩展性、高效性、高容错性。&lt;/p&gt;&#xA;&lt;h2 id=&#34;hadoop的构成&#34;&gt;&#xA;    Hadoop的构成&lt;a class=&#34;hash-link&#34; href=&#34;#hadoop%e7%9a%84%e6%9e%84%e6%88%90&#34; title=&#34;Direct link to heading&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&lt;p&gt;经过多年发展，hadoop已经成为以MapReduce和HDFS为核心的很多个项目的集合，包括Common、Avro、Chukwa、Hive、HBase等都对hadoop提供了互补性服务或在核心层上提供了更高层的服务。在主要讲解MapReduce之前，让我们先简要的看一下各项目的功能。&lt;/p&gt;&#xA;&lt;p&gt;Core：一套分布式文件系统以及支持Map-Reduce的计算框架；&lt;/p&gt;&#xA;&lt;p&gt;Avro：定义了一种用于支持大数据应用的数据格式，并为这种格式提供了不同的编程语言的支持；&lt;/p&gt;&#xA;&lt;p&gt;HDFS：Hadoop分布式文件系统；&lt;/p&gt;&#xA;&lt;p&gt;Map/Reduce**：**是一个使用简易的软件框架，基于它写出来的应用程序能够运行在由上千个商用机器组成的大型集群上，并以一种可靠容错的方式并行处理上T级别的数据集；&lt;/p&gt;&#xA;&lt;p&gt;ZooKeeper：是高可用的和可靠的分布式协同（coordination ）系统；&lt;/p&gt;&#xA;&lt;p&gt;Pig：建立于 Hadoop Core之上为并行计算环境提供了一套数据工作流语言和执行框架；&lt;/p&gt;&#xA;&lt;p&gt;Hive：是为提供简单的数据操作而设计的下一代分布式数据仓库。它提供了简单的类似SQL的语法的HiveQL语言进行数据查询；&lt;/p&gt;&#xA;&lt;p&gt;Hbase：建立于 Hadoop Core之上提供一个可扩展的数据库系统。&lt;/p&gt;&#xA;&lt;h1 id=&#34;mapreduce简介&#34;&gt;&#xA;    Map/Reduce简介&lt;a class=&#34;hash-link&#34; href=&#34;#mapreduce%e7%ae%80%e4%bb%8b&#34; title=&#34;Direct link to heading&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&lt;p&gt;MapReduce 是Google 公司的核心计算模型，它将运行于大规模集群上的复杂的并行计算过程高度地抽象为两个函数：Map 和Reduce。Hadoop 中的MapReduce 是一个使用简易的软件框架，基于它写出来的应用程序能够运行在由上千台商用机器组成的大型集群上，并以一种可靠容错的方式并行处理上T 级别的数据集，实现了Hadoop 在集群上的数据和任务的并行计算与处理。&lt;/p&gt;&#xA;&lt;p&gt;一个Map/Reduce 作业（Job）通常会把输入的数据集切分为若干独立的数据块，由Map任务（Task）以完全并行的方式处理它们。框架会先对Map 的输出进行排序，然后把结果输&lt;/p&gt;&#xA;&lt;p&gt;入给Reduce 任务。通常作业的输入和输出都会被存储在文件系统中。整个框架负责任务的&lt;/p&gt;&#xA;&lt;p&gt;调度和监控，以及重新执行已经失败的任务。&lt;/p&gt;&#xA;&lt;p&gt;通常，Map/Reduce 框架和分布式文件系统是运行在一组相同的节点上的，也就是说，计算节点和存储节点在一起。这种配置允许框架在那些已经存好数据的节点上高效地调度任务，这样可以使整个集群的网络带宽得到非常高效的利用。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
